{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "import skimage.io as skio\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import SSLRS.utils as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def open_tif(fn, cls=torch.Tensor):\n",
    "    im = skio.imread(str(fn))/10000\n",
    "    im = im.transpose(1,2,0).astype('float32')\n",
    "    return im\n",
    "class MSTensorImage(TensorImage):   \n",
    "    @classmethod\n",
    "    def create(cls, data:(Path,str,ndarray), chnls=None):\n",
    "        \n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            if str(data).endswith('tif'): im = open_tif(fn=data,cls=torch.Tensor)\n",
    "\n",
    "        elif isinstance(data, ndarray): \n",
    "            im = torch.from_numpy(data)\n",
    "        else:\n",
    "            im = data\n",
    "        \n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "BAND_STATS = {\n",
    "            'S2':{\n",
    "                'mean': {\n",
    "                    'B01': 340.76769064,\n",
    "                    'B02': 429.9430203,\n",
    "                    'B03': 614.21682446,\n",
    "                    'B04': 590.23569706,\n",
    "                    'B05': 950.68368468,\n",
    "                    'B06': 1792.46290469,\n",
    "                    'B07': 2075.46795189,\n",
    "                    'B08': 2218.94553375,\n",
    "                    'B8A': 2266.46036911,\n",
    "                    'B09': 2246.0605464,\n",
    "                    'B11': 1594.42694882,\n",
    "                    'B12': 1009.32729131\n",
    "                },\n",
    "                'std': {\n",
    "                    'B01': 554.81258967,\n",
    "                    'B02': 572.41639287,\n",
    "                    'B03': 582.87945694,\n",
    "                    'B04': 675.88746967,\n",
    "                    'B05': 729.89827633,\n",
    "                    'B06': 1096.01480586,\n",
    "                    'B07': 1273.45393088,\n",
    "                    'B08': 1365.45589904,\n",
    "                    'B8A': 1356.13789355,\n",
    "                    'B09': 1302.3292881,\n",
    "                    'B11': 1079.19066363,\n",
    "                    'B12': 818.86747235\n",
    "                }\n",
    "            },\n",
    "            'S1': {\n",
    "                'mean': {\n",
    "                    'VV': -12.619993741972035,\n",
    "                    'VH': -19.29044597721542,\n",
    "                    'VV/VH': 0.6525036195871579,\n",
    "                },\n",
    "                'std': {\n",
    "                    'VV': 5.115911777546365,\n",
    "                    'VH': 5.464428464912864,\n",
    "                    'VV/VH': 30.75264076801808,\n",
    "                },\n",
    "                'min': {\n",
    "                    'VV': -74.33214569091797,\n",
    "                    'VH': -75.11137390136719,\n",
    "                    'R': 3.21E-2\n",
    "                },\n",
    "                'max': {\n",
    "                    'VV': 34.60696029663086,\n",
    "                    'VH': 33.59768295288086,\n",
    "                    'R': 1.08\n",
    "                }\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bands=['B02','B03', 'B04', 'B05','B06', 'B07', 'B11', 'B08','B8A', 'B12']\n",
    "means=[BAND_STATS['S2']['mean'][band]/10000 for band in bands]\n",
    "stds=[BAND_STATS['S2']['std'][band]/10000 for band in bands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-332eb4238297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                       \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#                       A.Solarize(threshold=0.5),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                       \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_pixel_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                          ToTensorV2()]                    \n\u001b[1;32m     26\u001b[0m                     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'means' is not defined"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "import random\n",
    "class Channelaug(ImageOnlyTransform):\n",
    "\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(Channelaug, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        temp=img[:,:,random.randint(0,9),np.newaxis]\n",
    "        return np.repeat(temp,10,axis=2)\n",
    "\n",
    "\n",
    "trainaug=[]\n",
    "# first gobal crop\n",
    "globalaug1 = A.Compose([Channelaug(p=0.2),A.HorizontalFlip(p=0.5),\n",
    "                      A.ShiftScaleRotate(p=.5),\n",
    "                      A.RandomResizedCrop(120,120,scale=(0.4, 1.),always_apply=True),\n",
    "                      A.GaussianBlur(p=1.0),\n",
    "#                       A.Solarize(threshold=0.5),\n",
    "                      A.Normalize(mean=means,std=stds,max_pixel_value=1.0),\n",
    "                         ToTensorV2()]                    \n",
    "                    )\n",
    "\n",
    "# second global crop\n",
    "globalaug2 = A.Compose([Channelaug(p=0.2),A.HorizontalFlip(p=0.5),\n",
    "                      A.ShiftScaleRotate(p=.5),\n",
    "                      A.RandomResizedCrop(120,120,scale=(0.4, 1.),always_apply=True),\n",
    "                      A.GaussianBlur(p=0.1),\n",
    "                      A.Solarize(threshold=0.5,p=0.2),\n",
    "                      A.Normalize(mean=means,std=stds,max_pixel_value=1.0),\n",
    "                         ToTensorV2()]                    \n",
    "                    )\n",
    "# transformation for the local small crops\n",
    "\n",
    "locaaug = A.Compose([Channelaug(p=0.2),A.HorizontalFlip(p=0.5),\n",
    "                      A.ShiftScaleRotate(p=.5),\n",
    "                      A.RandomResizedCrop(56,56,scale=(0.05, 0.4),always_apply=True),\n",
    "                      A.GaussianBlur(p=0.5),\n",
    "                      A.Normalize(mean=means,std=stds,max_pixel_value=1.0),\n",
    "                         ToTensorV2()]                    \n",
    "                    )\n",
    "\n",
    "\n",
    "trainaug.append(globalaug1)\n",
    "trainaug.append(globalaug2)\n",
    "for _ in range(6):\n",
    "    trainaug.append(locaaug)\n",
    "\n",
    "val_pipe = A.Compose([\n",
    "    A.Normalize(mean=means,std=stds,max_pixel_value=1.0),\n",
    "                         ToTensorV2()]                    \n",
    "                    )\n",
    "\n",
    "class TrainTransform(ItemTransform):\n",
    "    split_idx = 0\n",
    "    def __init__(self, aug,split=0): \n",
    "        self.aug = aug\n",
    "#         self.split_idx = split\n",
    "    def encodes(self, x):\n",
    "        result=[]\n",
    "        for i in range(len(self.aug)):\n",
    "            result.append(self.aug[i](image=x[0])['image'])\n",
    "        return result, x[1]\n",
    "class ValTransform(ItemTransform):\n",
    "    split_idx = 1\n",
    "    def __init__(self, aug,split=0): \n",
    "        self.aug = aug\n",
    "#         self.split_idx = split\n",
    "    def encodes(self, x):\n",
    "        aug = self.aug(image=x[0])\n",
    "#         print(torch.cat((aug['image0'],aug['image1']),axis=0).shape)\n",
    "        return aug['image'], x[1]\n",
    "\n",
    "# Create our class with this aug_pipe\n",
    "aug = TrainTransform(trainaug)\n",
    "aug2=ValTransform(val_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "db = DataBlock(blocks=(TransformBlock(type_tfms=partial(MSTensorImage.create)),CategoryBlock),\n",
    "                   splitter=ColSplitter('Isval'),\n",
    "                   get_x=ColReader('fname'),\n",
    "                   get_y=ColReader('labels'),\n",
    "                   item_tfms=[aug,aug2]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/file.csv')\n",
    "newdf=pd.concat([df[df['Isval']==0].sample(frac=0.05,random_state=10),df[df['Isval']==1]])\n",
    "newdf['labels']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = db.dataloaders(source=newdf, bs=2, num_workers=8,drop_last=True,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.distributed import *\n",
    "dl1 = DistributedDL(dls, 0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 04_data.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script(fname='./04_data.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
