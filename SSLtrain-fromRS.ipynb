{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSLRS.dataset import *\n",
    "import pandas as pd\n",
    "from fastai.distributed import *\n",
    "from fastai.vision.all import DataLoader\n",
    "import torch\n",
    "import SSLRS.utils as utils\n",
    "from SSLRS.visiontrans import DINOHead\n",
    "from torch.utils.data import Dataset\n",
    "# dl1 = DistributedDL(dls, 0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/file.csv')\n",
    "newdf=df[df['Isval']==0].sample(frac=0.05,random_state=10)\n",
    "newdf['labels']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Isval</th>\n",
       "      <th>label</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178815</th>\n",
       "      <td>./data/BigEarthNet-v1.0/S2B_MSIL2A_20170924T093019_45_63/S2B_MSIL2A_20170924T093019_45_63.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>2 5 6 10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23217</th>\n",
       "      <td>./data/BigEarthNet-v1.0/S2A_MSIL2A_20170816T095031_1_11/S2A_MSIL2A_20170816T095031_1_11.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229767</th>\n",
       "      <td>./data/BigEarthNet-v1.0/S2B_MSIL2A_20180326T112109_75_47/S2B_MSIL2A_20180326T112109_75_47.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>2 4 5 6 7 8 13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97130</th>\n",
       "      <td>./data/BigEarthNet-v1.0/S2A_MSIL2A_20171104T095201_12_34/S2A_MSIL2A_20171104T095201_12_34.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>0 2 8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198670</th>\n",
       "      <td>./data/BigEarthNet-v1.0/S2B_MSIL2A_20170817T101019_44_34/S2B_MSIL2A_20170817T101019_44_34.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                fname  \\\n",
       "178815  ./data/BigEarthNet-v1.0/S2B_MSIL2A_20170924T093019_45_63/S2B_MSIL2A_20170924T093019_45_63.tif   \n",
       "23217     ./data/BigEarthNet-v1.0/S2A_MSIL2A_20170816T095031_1_11/S2A_MSIL2A_20170816T095031_1_11.tif   \n",
       "229767  ./data/BigEarthNet-v1.0/S2B_MSIL2A_20180326T112109_75_47/S2B_MSIL2A_20180326T112109_75_47.tif   \n",
       "97130   ./data/BigEarthNet-v1.0/S2A_MSIL2A_20171104T095201_12_34/S2A_MSIL2A_20171104T095201_12_34.tif   \n",
       "198670  ./data/BigEarthNet-v1.0/S2B_MSIL2A_20170817T101019_44_34/S2B_MSIL2A_20170817T101019_44_34.tif   \n",
       "\n",
       "        Isval           label  labels  \n",
       "178815      0        2 5 6 10       1  \n",
       "23217       0              18       1  \n",
       "229767      0  2 4 5 6 7 8 13       1  \n",
       "97130       0           0 2 8       1  \n",
       "198670      0              18       1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rsdata(Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths['fname'].iloc[idx]\n",
    "        image=open_tif(image_filepath)\n",
    "        label = self.images_filepaths['labels'].iloc[idx]\n",
    "        if self.transform is not None:\n",
    "            result=[]\n",
    "            for i in range(len(self.transform)):\n",
    "                result.append(self.transform[i](image=image)['image'])\n",
    "        return result, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Rsdata(newdf, transform=trainaug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=12,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=first(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first(x, f=None, negate=False, **kwargs):\n",
    "    \"First element of `x`, optionally filtered by `f`, or None if missing\"\n",
    "    x = iter(x)\n",
    "    if f: x = filter_ex(x, f=f, negate=negate, gen=True, **kwargs)\n",
    "    return next(x, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=timm.create_model('xcit_small_12_p8_224',num_classes=0, in_chans=10,drop_path_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = timm.create_model('xcit_small_12_p8_224',num_classes=0, in_chans=10,drop_path_rate=0.1)\n",
    "teacher = timm.create_model('xcit_small_12_p8_224',num_classes=0, in_chans=10)\n",
    "embed_dim = student.embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0a2227c52ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtorchvision_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorchvision_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision import models as torchvision_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student=xresnet18(c_in=10)\n",
    "student[11]=nn.Identity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = utils.MultiCropWrapper(student, DINOHead(\n",
    "    512,\n",
    "    2**16,\n",
    "    use_bn=False,\n",
    "    norm_last_layer=True,\n",
    "))\n",
    "# teacher = utils.MultiCropWrapper(\n",
    "#     teacher,\n",
    "#     DINOHead(embed_dim, 2**16, use_bn=False),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=torch.ones(1,10,120,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0150,  0.0144, -0.0184,  ..., -0.0575, -0.0004,  0.0712]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dino(args):\n",
    "    utils.init_distributed_mode(args)\n",
    "    utils.fix_random_seeds(args.seed)\n",
    "    print(\"git:\\n  {}\\n\".format(utils.get_sha()))\n",
    "    print(\"\\n\".join(\"%s: %s\" % (k, str(v)) for k, v in sorted(dict(vars(args)).items())))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # ============ preparing data ... ============\n",
    "    df=pd.read_csv('./data/file.csv')\n",
    "    newdf=pd.concat([df[df['Isval']==0].sample(frac=0.05,random_state=10),df[df['Isval']==1]])\n",
    "    newdf['labels']=1\n",
    "    data_loader = db.dataloaders(source=newdf, bs=args.batch_size_per_gpu, num_workers=args.num_workers,drop_last=True,pin_memory=True)\n",
    "    data_loader=DistributedDL(data_loader.train)\n",
    "#     print(f\"Data loaded: there are {len(dataset)} images.\")\n",
    "\n",
    "    # ============ building student and teacher networks ... ============\n",
    "    student = timm.create_model('xcit_small_12_p8_224',num_classes=0, in_chans=10,drop_path_rate=0.1)\n",
    "    teacher = timm.create_model('xcit_small_12_p8_224',num_classes=0, in_chans=10)\n",
    "    embed_dim = student.embed_dim\n",
    "    student = utils.MultiCropWrapper(student, DINOHead(\n",
    "    embed_dim,\n",
    "    2**16,\n",
    "    use_bn=False,\n",
    "    norm_last_layer=True,))\n",
    "    teacher = utils.MultiCropWrapper(\n",
    "    teacher,\n",
    "    DINOHead(embed_dim, 2**16, use_bn=False))\n",
    "    # move networks to gpu\n",
    "    student, teacher = student.cuda(), teacher.cuda()\n",
    "    # synchronize batch norms (if any)\n",
    "    if utils.has_batchnorms(student):\n",
    "        student = nn.SyncBatchNorm.convert_sync_batchnorm(student)\n",
    "        teacher = nn.SyncBatchNorm.convert_sync_batchnorm(teacher)\n",
    "\n",
    "        # we need DDP wrapper to have synchro batch norms working...\n",
    "        teacher = nn.parallel.DistributedDataParallel(teacher, device_ids=[args.gpu])\n",
    "        teacher_without_ddp = teacher.module\n",
    "    else:\n",
    "        # teacher_without_ddp and teacher are the same thing\n",
    "        teacher_without_ddp = teacher\n",
    "    student = nn.parallel.DistributedDataParallel(student, device_ids=[args.gpu])\n",
    "    # teacher and student start with the same weights\n",
    "    teacher_without_ddp.load_state_dict(student.module.state_dict())\n",
    "    # there is no backpropagation through the teacher, so no need for gradients\n",
    "    for p in teacher.parameters():\n",
    "        p.requires_grad = False\n",
    "    print(f\"Student and Teacher are built: they are both {args.arch} network.\")\n",
    "\n",
    "    # ============ preparing loss ... ============\n",
    "    dino_loss = DINOLoss(\n",
    "        args.out_dim,\n",
    "        args.local_crops_number + 2,  # total number of crops = 2 global crops + local_crops_number\n",
    "        args.warmup_teacher_temp,\n",
    "        args.teacher_temp,\n",
    "        args.warmup_teacher_temp_epochs,\n",
    "        args.epochs,\n",
    "    ).cuda()\n",
    "\n",
    "    # ============ preparing optimizer ... ============\n",
    "    params_groups = utils.get_params_groups(student)\n",
    "    if args.optimizer == \"adamw\":\n",
    "        optimizer = torch.optim.AdamW(params_groups)  # to use with ViTs\n",
    "    elif args.optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(params_groups, lr=0, momentum=0.9)  # lr is set by scheduler\n",
    "    elif args.optimizer == \"lars\":\n",
    "        optimizer = utils.LARS(params_groups)  # to use with convnet and large batches\n",
    "    # for mixed precision training\n",
    "    fp16_scaler = None\n",
    "    if args.use_fp16:\n",
    "        fp16_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # ============ init schedulers ... ============\n",
    "    lr_schedule = utils.cosine_scheduler(\n",
    "        args.lr * (args.batch_size_per_gpu * utils.get_world_size()) / 256.,  # linear scaling rule\n",
    "        args.min_lr,\n",
    "        args.epochs, len(data_loader),\n",
    "        warmup_epochs=args.warmup_epochs,\n",
    "    )\n",
    "    wd_schedule = utils.cosine_scheduler(\n",
    "        args.weight_decay,\n",
    "        args.weight_decay_end,\n",
    "        args.epochs, len(data_loader),\n",
    "    )\n",
    "    # momentum parameter is increased to 1. during training with a cosine schedule\n",
    "    momentum_schedule = utils.cosine_scheduler(args.momentum_teacher, 1,\n",
    "                                               args.epochs, len(data_loader))\n",
    "    print(f\"Loss, optimizer and schedulers ready.\")\n",
    "\n",
    "    # ============ optionally resume training ... ============\n",
    "    to_restore = {\"epoch\": 0}\n",
    "    utils.restart_from_checkpoint(\n",
    "        os.path.join(args.output_dir, \"checkpoint.pth\"),\n",
    "        run_variables=to_restore,\n",
    "        student=student,\n",
    "        teacher=teacher,\n",
    "        optimizer=optimizer,\n",
    "        fp16_scaler=fp16_scaler,\n",
    "        dino_loss=dino_loss,\n",
    "    )\n",
    "    start_epoch = to_restore[\"epoch\"]\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Starting DINO training !\")\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        # ============ training one epoch of DINO ... ============\n",
    "        train_stats = train_one_epoch(student, teacher, teacher_without_ddp, dino_loss,\n",
    "            data_loader, optimizer, lr_schedule, wd_schedule, momentum_schedule,\n",
    "            epoch, fp16_scaler, args)\n",
    "\n",
    "        # ============ writing logs ... ============\n",
    "        save_dict = {\n",
    "            'student': student.state_dict(),\n",
    "            'teacher': teacher.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch + 1,\n",
    "            'args': args,\n",
    "            'dino_loss': dino_loss.state_dict(),\n",
    "        }\n",
    "        if fp16_scaler is not None:\n",
    "            save_dict['fp16_scaler'] = fp16_scaler.state_dict()\n",
    "        utils.save_on_master(save_dict, os.path.join(args.output_dir, 'checkpoint.pth'))\n",
    "        if args.saveckp_freq and epoch % args.saveckp_freq == 0:\n",
    "            utils.save_on_master(save_dict, os.path.join(args.output_dir, f'checkpoint{epoch:04}.pth'))\n",
    "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                     'epoch': epoch}\n",
    "        if utils.is_main_process():\n",
    "            with (Path(args.output_dir) / \"log.txt\").open(\"a\") as f:\n",
    "                f.write(json.dumps(log_stats) + \"\\n\")\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.has_batchnorms(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
